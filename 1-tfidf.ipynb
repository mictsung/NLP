{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "65a93f35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in /Users/mickey/opt/anaconda3/lib/python3.8/site-packages (3.6.1)\n",
      "Requirement already satisfied: tqdm in /Users/mickey/opt/anaconda3/lib/python3.8/site-packages (from nltk) (4.59.0)\n",
      "Requirement already satisfied: regex in /Users/mickey/opt/anaconda3/lib/python3.8/site-packages (from nltk) (2021.4.4)\n",
      "Requirement already satisfied: click in /Users/mickey/opt/anaconda3/lib/python3.8/site-packages (from nltk) (7.1.2)\n",
      "Requirement already satisfied: joblib in /Users/mickey/opt/anaconda3/lib/python3.8/site-packages (from nltk) (1.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9b37b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph=\"\"\"Internal polls that show Harris would at least be more helpful to boosting Democratic enthusiasm and aiding down ballot races are getting passed around. Arguments that she would be fastest to put together a campaign are landing harder. Daydreams of her making a more active and vigorous case against Donald Trump are taking root.\n",
    "Many are deliberately holding off talking about hypotheticals as Biden aides say he plans to get back on the campaign trail next week once he recovers from Covid-19. But if that suddenly changes, two dozen leading Democratic politicians and operatives told CNN, they can’t realistically see this ending any other way.\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e8d802e6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Internal polls that show Harris would at least be more helpful to boosting Democratic enthusiasm and aiding down ballot races are getting passed around. Arguments that she would be fastest to put together a campaign are landing harder. Daydreams of her making a more active and vigorous case against Donald Trump are taking root.\\nMany are deliberately holding off talking about hypotheticals as Biden aides say he plans to get back on the campaign trail next week once he recovers from Covid-19. But if that suddenly changes, two dozen leading Democratic politicians and operatives told CNN, they can’t realistically see this ending any other way.\"\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fe09423f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk \n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c56998c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/mickey/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "nltk.download('punkt')\n",
    "sentences=nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e1f1fa1f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Internal polls that show Harris would at least be more helpful to boosting Democratic enthusiasm and aiding down ballot races are getting passed around.',\n",
       " 'Arguments that she would be fastest to put together a campaign are landing harder.',\n",
       " 'Daydreams of her making a more active and vigorous case against Donald Trump are taking root.',\n",
       " 'Many are deliberately holding off talking about hypotheticals as Biden aides say he plans to get back on the campaign trail next week once he recovers from Covid-19.',\n",
       " 'But if that suddenly changes, two dozen leading Democratic politicians and operatives told CNN, they can’t realistically see this ending any other way.\"']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9f23e3f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Internal polls that show Harris would at least be more helpful to boosting Democratic enthusiasm and aiding down ballot races are getting passed around.', 'Arguments that she would be fastest to put together a campaign are landing harder.', 'Daydreams of her making a more active and vigorous case against Donald Trump are taking root.', 'Many are deliberately holding off talking about hypotheticals as Biden aides say he plans to get back on the campaign trail next week once he recovers from Covid-19.', 'But if that suddenly changes, two dozen leading Democratic politicians and operatives told CNN, they can’t realistically see this ending any other way.\"']\n"
     ]
    }
   ],
   "source": [
    "print(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fe7b655a",
   "metadata": {},
   "outputs": [],
   "source": [
    "stemmer=PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d15b4ca2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'go'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('going')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17d10c50",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'histori'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stemmer.stem('history')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "7710e6ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "a08657d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "499bd140",
   "metadata": {},
   "outputs": [
    {
     "ename": "LookupError",
     "evalue": "\n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/mickey/nltk_data'\n    - '/Users/mickey/opt/anaconda3/nltk_data'\n    - '/Users/mickey/opt/anaconda3/share/nltk_data'\n    - '/Users/mickey/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet.zip/wordnet/\u001b[0m\n\n  Searched in:\n    - '/Users/mickey/nltk_data'\n    - '/Users/mickey/opt/anaconda3/nltk_data'\n    - '/Users/mickey/opt/anaconda3/share/nltk_data'\n    - '/Users/mickey/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mLookupError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-26-2ce762533a00>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mlemmatizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'baby'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/stem/wordnet.py\u001b[0m in \u001b[0;36mlemmatize\u001b[0;34m(self, word, pos)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     37\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mlemmatize\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNOUN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m         \u001b[0mlemmas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwordnet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_morphy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlemmas\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mlemmas\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mword\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__getattr__\u001b[0;34m(self, attr)\u001b[0m\n\u001b[1;32m    118\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"LazyCorpusLoader object has no attribute '__bases__'\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    119\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 120\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    121\u001b[0m         \u001b[0;31m# This looks circular, but its not, since __load() changes our\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    122\u001b[0m         \u001b[0;31m# __class__ to something new:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     83\u001b[0m                     \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mzip_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     84\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 85\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     86\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m         \u001b[0;31m# Load the corpus.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/corpus/util.py\u001b[0m in \u001b[0;36m__load\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     78\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m                 \u001b[0mroot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnltk\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfind\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{}/{}\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msubdir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mLookupError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/opt/anaconda3/lib/python3.8/site-packages/nltk/data.py\u001b[0m in \u001b[0;36mfind\u001b[0;34m(resource_name, paths)\u001b[0m\n\u001b[1;32m    581\u001b[0m     \u001b[0msep\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"*\"\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;36m70\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0mresource_not_found\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"\\n%s\\n%s\\n%s\\n\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msep\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmsg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 583\u001b[0;31m     \u001b[0;32mraise\u001b[0m \u001b[0mLookupError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresource_not_found\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    584\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    585\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mLookupError\u001b[0m: \n**********************************************************************\n  Resource \u001b[93mwordnet\u001b[0m not found.\n  Please use the NLTK Downloader to obtain the resource:\n\n  \u001b[31m>>> import nltk\n  >>> nltk.download('wordnet')\n  \u001b[0m\n  For more information see: https://www.nltk.org/data.html\n\n  Attempted to load \u001b[93mcorpora/wordnet\u001b[0m\n\n  Searched in:\n    - '/Users/mickey/nltk_data'\n    - '/Users/mickey/opt/anaconda3/nltk_data'\n    - '/Users/mickey/opt/anaconda3/share/nltk_data'\n    - '/Users/mickey/opt/anaconda3/lib/nltk_data'\n    - '/usr/share/nltk_data'\n    - '/usr/local/share/nltk_data'\n    - '/usr/lib/nltk_data'\n    - '/usr/local/lib/nltk_data'\n**********************************************************************\n"
     ]
    }
   ],
   "source": [
    "lemmatizer.lemmatize('baby')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5393a35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "dad6bf76",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "57fad57c",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[]\n",
    "for i in range(len(sentences)):\n",
    "    review=re.sub('[^a-zA-Z]',' ',sentences[i])\n",
    "    review=review.lower()\n",
    "    corpus.append(review)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "d5ce0b78",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['internal polls that show harris would at least be more helpful to boosting democratic enthusiasm and aiding down ballot races are getting passed around ',\n",
       " 'arguments that she would be fastest to put together a campaign are landing harder ',\n",
       " 'daydreams of her making a more active and vigorous case against donald trump are taking root ',\n",
       " 'many are deliberately holding off talking about hypotheticals as biden aides say he plans to get back on the campaign trail next week once he recovers from covid    ',\n",
       " 'but if that suddenly changes  two dozen leading democratic politicians and operatives told cnn  they can t realistically see this ending any other way  ']"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "2edc5e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mickey/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /Users/mickey/nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "258e9f3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "intern\n",
      "poll\n",
      "show\n",
      "harri\n",
      "would\n",
      "least\n",
      "help\n",
      "boost\n",
      "democrat\n",
      "enthusiasm\n",
      "aid\n",
      "ballot\n",
      "race\n",
      "get\n",
      "pass\n",
      "around\n",
      "argument\n",
      "would\n",
      "fastest\n",
      "put\n",
      "togeth\n",
      "campaign\n",
      "land\n",
      "harder\n",
      "daydream\n",
      "make\n",
      "activ\n",
      "vigor\n",
      "case\n",
      "donald\n",
      "trump\n",
      "take\n",
      "root\n",
      "mani\n",
      "deliber\n",
      "hold\n",
      "talk\n",
      "hypothet\n",
      "biden\n",
      "aid\n",
      "say\n",
      "plan\n",
      "get\n",
      "back\n",
      "campaign\n",
      "trail\n",
      "next\n",
      "week\n",
      "recov\n",
      "covid\n",
      "suddenli\n",
      "chang\n",
      "two\n",
      "dozen\n",
      "lead\n",
      "democrat\n",
      "politician\n",
      "oper\n",
      "told\n",
      "cnn\n",
      "realist\n",
      "see\n",
      "end\n",
      "way\n"
     ]
    }
   ],
   "source": [
    "##stemming\n",
    "for i in corpus:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words: \n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(stemmer.stem(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8c7c4219",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "internal\n",
      "poll\n",
      "show\n",
      "harris\n",
      "would\n",
      "least\n",
      "helpful\n",
      "boosting\n",
      "democratic\n",
      "enthusiasm\n",
      "aiding\n",
      "ballot\n",
      "race\n",
      "getting\n",
      "passed\n",
      "around\n",
      "argument\n",
      "would\n",
      "fastest\n",
      "put\n",
      "together\n",
      "campaign\n",
      "landing\n",
      "harder\n",
      "daydream\n",
      "making\n",
      "active\n",
      "vigorous\n",
      "case\n",
      "donald\n",
      "trump\n",
      "taking\n",
      "root\n",
      "many\n",
      "deliberately\n",
      "holding\n",
      "talking\n",
      "hypothetical\n",
      "biden\n",
      "aide\n",
      "say\n",
      "plan\n",
      "get\n",
      "back\n",
      "campaign\n",
      "trail\n",
      "next\n",
      "week\n",
      "recovers\n",
      "covid\n",
      "suddenly\n",
      "change\n",
      "two\n",
      "dozen\n",
      "leading\n",
      "democratic\n",
      "politician\n",
      "operative\n",
      "told\n",
      "cnn\n",
      "realistically\n",
      "see\n",
      "ending\n",
      "way\n"
     ]
    }
   ],
   "source": [
    "##stemming\n",
    "for i in corpus:\n",
    "    words = nltk.word_tokenize(i)\n",
    "    for word in words: \n",
    "        if word not in set(stopwords.words('english')):\n",
    "            print(lemmatizer.lemmatize(word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "43a1b9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "## BOW \n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "cv = CountVectorizer(binary=True,ngram_range=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "a56aebcd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "11e995af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'internal': 44,\n",
       " 'polls': 61,\n",
       " 'that': 74,\n",
       " 'show': 70,\n",
       " 'harris': 37,\n",
       " 'would': 87,\n",
       " 'at': 11,\n",
       " 'least': 47,\n",
       " 'be': 14,\n",
       " 'more': 50,\n",
       " 'helpful': 39,\n",
       " 'to': 78,\n",
       " 'boosting': 16,\n",
       " 'democratic': 26,\n",
       " 'enthusiasm': 31,\n",
       " 'and': 5,\n",
       " 'aiding': 4,\n",
       " 'down': 28,\n",
       " 'ballot': 13,\n",
       " 'races': 63,\n",
       " 'are': 7,\n",
       " 'getting': 35,\n",
       " 'passed': 58,\n",
       " 'around': 9,\n",
       " 'arguments': 8,\n",
       " 'she': 69,\n",
       " 'fastest': 32,\n",
       " 'put': 62,\n",
       " 'together': 79,\n",
       " 'campaign': 18,\n",
       " 'landing': 45,\n",
       " 'harder': 36,\n",
       " 'daydreams': 24,\n",
       " 'of': 52,\n",
       " 'her': 40,\n",
       " 'making': 48,\n",
       " 'active': 1,\n",
       " 'vigorous': 84,\n",
       " 'case': 20,\n",
       " 'against': 2,\n",
       " 'donald': 27,\n",
       " 'trump': 82,\n",
       " 'taking': 72,\n",
       " 'root': 66,\n",
       " 'many': 49,\n",
       " 'deliberately': 25,\n",
       " 'holding': 41,\n",
       " 'off': 53,\n",
       " 'talking': 73,\n",
       " 'about': 0,\n",
       " 'hypotheticals': 42,\n",
       " 'as': 10,\n",
       " 'biden': 15,\n",
       " 'aides': 3,\n",
       " 'say': 67,\n",
       " 'he': 38,\n",
       " 'plans': 59,\n",
       " 'get': 34,\n",
       " 'back': 12,\n",
       " 'on': 54,\n",
       " 'the': 75,\n",
       " 'trail': 81,\n",
       " 'next': 51,\n",
       " 'week': 86,\n",
       " 'once': 55,\n",
       " 'recovers': 65,\n",
       " 'from': 33,\n",
       " 'covid': 23,\n",
       " 'but': 17,\n",
       " 'if': 43,\n",
       " 'suddenly': 71,\n",
       " 'changes': 21,\n",
       " 'two': 83,\n",
       " 'dozen': 29,\n",
       " 'leading': 46,\n",
       " 'politicians': 60,\n",
       " 'operatives': 56,\n",
       " 'told': 80,\n",
       " 'cnn': 22,\n",
       " 'they': 76,\n",
       " 'can': 19,\n",
       " 'realistically': 64,\n",
       " 'see': 68,\n",
       " 'this': 77,\n",
       " 'ending': 30,\n",
       " 'any': 6,\n",
       " 'other': 57,\n",
       " 'way': 85}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##index\n",
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "89d91c24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'internal polls that show harris would at least be more helpful to boosting democratic enthusiasm and aiding down ballot races are getting passed around '"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "d584738c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "        1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "78c1f005",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "2d1d6916",
   "metadata": {},
   "outputs": [],
   "source": [
    "# max_features: shows the hole corpus top-n high frequency features \n",
    "\n",
    "cv=TfidfVectorizer(ngram_range=(1,1), max_features=3)\n",
    "X=cv.fit_transform(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "0b415aef",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'that': 1, 'to': 2, 'are': 0}"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "6701c550",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'internal polls that show harris would at least be more helpful to boosting democratic enthusiasm and aiding down ballot races are getting passed around '"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "89bec370",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.        , 0.        , 0.        , 0.        , 0.21320072,\n",
       "        0.21320072, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21320072, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.21320072, 0.        , 0.21320072, 0.        , 0.21320072,\n",
       "        0.        , 0.21320072, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.21320072, 0.        , 0.        , 0.21320072,\n",
       "        0.        , 0.        , 0.21320072, 0.        , 0.        ,\n",
       "        0.21320072, 0.21320072, 0.        , 0.        , 0.21320072,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21320072,\n",
       "        0.        , 0.21320072, 0.        , 0.        , 0.        ,\n",
       "        0.21320072, 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.21320072,\n",
       "        0.        , 0.21320072, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.21320072, 0.        , 0.        ,\n",
       "        0.        , 0.21320072, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.21320072, 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "        0.        , 0.21320072, 0.        ]])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0].toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "025d9980",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
